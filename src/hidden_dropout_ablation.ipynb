{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581ec357-ffd4-4a18-972d-49a6033115f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformers is installed\n",
      "datasets is installed\n",
      "soundfile is installed\n",
      "librosa is installed\n",
      "evaluate is installed\n",
      "jiwer is installed\n",
      "accelerate is installed\n",
      "pandas is installed\n",
      "wandb is installed\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets soundfile librosa evaluate jiwer kaggle accelerate\n",
    "!pip install pandas\n",
    "!pip install huggingface_hub\n",
    "!pip install wandb\n",
    "!pip install transformers\n",
    "!pip uninstall torch torchvision torchaudio -y\n",
    "!pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu118\n",
    "\n",
    "\n",
    "import importlib.util\n",
    "reqs=['transformers', 'datasets', 'soundfile', 'librosa', 'evaluate', 'jiwer', 'accelerate','pandas','wandb']\n",
    "def check_installed(packages):\n",
    "    for pkg in packages:\n",
    "        try:\n",
    "            importlib.import_module(pkg)\n",
    "            print(f\"{pkg} is installed\")\n",
    "        except ImportError:\n",
    "            print(f\"{pkg} is NOT installed\")\n",
    "check_installed(reqs)\n",
    "\n",
    "import torch, transformers\n",
    "print(f\"PyTorch: {torch.__version__}\")  \n",
    "print(f\"Transformers: {transformers.__version__}\")\n",
    "\n",
    "# DTensor check\n",
    "try:\n",
    "    from torch.distributed.tensor import DTensor\n",
    "    print(\" DTensor available\")\n",
    "except ImportError:\n",
    "    raise RuntimeError(\" DTensor not found - upgrade PyTorch!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a054fb-431e-4e4d-bb4b-7038c4c224b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "from datasets import Dataset, Audio\n",
    "from transformers import (\n",
    "    Wav2Vec2FeatureExtractor,\n",
    "    Wav2Vec2Processor,\n",
    "    Wav2Vec2ForCTC,\n",
    "    Wav2Vec2CTCTokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "import torch\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Union\n",
    "import evaluate \n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from transformers import AutoProcessor, AutoModelForCTC\n",
    "import wandb\n",
    "from datetime import datetime\n",
    "import re\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a9d409-dddf-417e-b611-067b3884e193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from: /workspace/datasets/processed_json_dataset/combined_dataset.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cb8c0874ff54b0499a450d0b4f1c660",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 20476 samples\n",
      "Normalizing absolute paths to real audio files...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee34fe91a6514aa9a4f61497011f13ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20476 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding audio...\n",
      "Audio decoding complete!\n",
      "Sample entry: {'audio': {'path': '/workspace/datasets/preparedDataset/dataset_new/clips/telugu_000001.wav', 'array': array([-0.00268555, -0.0017395 , -0.00143433, ...,  0.19799805,\n",
      "        0.19128418,  0.18591309]), 'sampling_rate': 16000}, 'transcription': 'పరీక్షల అంశంపై పునరాలోచించాలని రాష్ట్ర ప్రభుత్వానికి సూచించింది'}\n"
     ]
    }
   ],
   "source": [
    "json_path = \"PATH_TO_DATASET/processed_json/combined_dataset.json\"\n",
    "AUDIO_BASE_PATH = \"PATH_TO_DATASET/extracted/audio_files\"\n",
    "SAMPLING_RATE = 16000\n",
    "\n",
    "print(f\"Loading dataset from: {json_path}\")\n",
    "dataset = load_dataset(\"json\", data_files=json_path, split=\"train\")\n",
    "print(f\"Loaded dataset with {len(dataset)} samples\")\n",
    "\n",
    "print(\"Normalizing absolute paths to real audio files...\")\n",
    "\n",
    "def normalize_audio_path(example):\n",
    "    relative_filename = example[\"audio\"].split(\"clips/\")[-1]\n",
    "    example[\"audio\"] = os.path.join(AUDIO_BASE_PATH, \"clips\", relative_filename)\n",
    "    return example\n",
    "\n",
    "dataset = dataset.map(normalize_audio_path)\n",
    "\n",
    "data = [{\"audio\": x[\"audio\"], \"sentence\": x[\"transcription\"]} for x in dataset]\n",
    "train_data, val_data = train_test_split(data, test_size=0.1, random_state=42)\n",
    "\n",
    "train_dataset = Dataset.from_list(train_data)\n",
    "val_dataset = Dataset.from_list(val_data)\n",
    "train_dataset = train_dataset.cast_column(\"audio\", Audio(sampling_rate=SAMPLING_RATE))\n",
    "val_dataset = val_dataset.cast_column(\"audio\", Audio(sampling_rate=SAMPLING_RATE))\n",
    "print(\"Audio decoding complete!\")\n",
    "print(\"Sample entry:\", train_dataset[0])\n",
    "print(f\"Train set size: {len(train_dataset)}\")\n",
    "print(f\" Validation set size: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5073294-6be9-4f81-b8ce-ee441058ad53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a85eca977ed4e93adc65886908fc0d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20476 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "telugu_special_unwanted_characters = [\n",
    "    'ఁ', 'ౄ', 'ౢ', 'ౣ', 'ౠ', 'ఽ',\n",
    "    '౦', '౧', '౨', '౩', '౪', '౫', '౬', '౭', '౮', '౯',\n",
    "    'ఀ', 'ౘ', 'ౙ', 'ౚ', '౷',\n",
    "    '‘', '’', '“', '”', '%', '.', ';', '-', ',', '/', '\\\\', '_', '&',\n",
    "    'G', 'P', 'S', 'e', 'l', 'n', 'r', 't', '\\u200c', '\\n'\n",
    "]\n",
    "\n",
    "chars_to_remove_regex = f\"[{re.escape(''.join(telugu_special_unwanted_characters))}]\"\n",
    "def remove_special_characters(batch):\n",
    "    batch[\"sentence\"] = re.sub(chars_to_remove_regex, '', batch[\"sentence\"])\n",
    "    return batch\n",
    "\n",
    "train_dataset = train_dataset.map(remove_special_characters)\n",
    "val_dataset   = val_dataset.map(remove_special_characters)\n",
    "\n",
    "print(\"Special characters removed from 'sentence' column.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3035e0-5a50-4f08-8729-cc9537aad5ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "103fc4ef37ae414fbf495b5c7eb5eddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/256 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0d7cdb9c1fc47e1a2c7afca08c67c9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5b89d66b7bc45e5ac3478fd3d1b811c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/985 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72d1bcb3b4f14d778c97871f70d062d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/45.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99dc088237914adf9f7195c5d36b6c0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/548 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_repo_name = \"PATH_TO_REPO\"\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(base_repo_name)\n",
    "model = AutoModelForCTC.from_pretrained(base_repo_name).to(\"cuda\")\n",
    "model.freeze_feature_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9738518-43aa-490a-b46b-74fc1e9df73c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfb1a881ef84479096301e7489a2d568",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/18428 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "414a87e68f84462183ede1c189a27fbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/2048 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets prepared and tokenized.\n"
     ]
    }
   ],
   "source": [
    "def prepare_dataset(batch):\n",
    "    audio = batch[\"audio\"]\n",
    "\n",
    "    batch[\"input_values\"] = processor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_values[0]\n",
    "    batch[\"input_length\"] = len(batch[\"input_values\"])\n",
    "    batch[\"labels\"] = processor.tokenizer(batch[\"sentence\"]).input_ids\n",
    "    return batch\n",
    "    \n",
    "train_dataset = train_dataset.map(\n",
    "    prepare_dataset,\n",
    "    remove_columns=train_dataset.column_names,\n",
    "    num_proc=4\n",
    ")\n",
    "\n",
    "val_dataset = val_dataset.map(\n",
    "    prepare_dataset,\n",
    "    remove_columns=val_dataset.column_names,\n",
    "    num_proc=4\n",
    ")\n",
    "\n",
    "print(\"Datasets prepared and tokenized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d43f080-8acd-4ead-a3db-2a761762fba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data collator ready.\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class DataCollatorCTCWithPadding:\n",
    "    processor: Wav2Vec2Processor\n",
    "    padding: Union[bool, str] = True\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        input_features = [{\"input_values\": f[\"input_values\"]} for f in features]\n",
    "        label_features = [{\"input_ids\": f[\"labels\"]} for f in features]\n",
    "        batch = self.processor.pad(\n",
    "            input_features,\n",
    "            padding=self.padding,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        with self.processor.as_target_processor():\n",
    "            labels_batch = self.processor.pad(\n",
    "                label_features,\n",
    "                padding=self.padding,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "\n",
    "        \n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "        return batch\n",
    "\n",
    "data_collator = DataCollatorCTCWithPadding(\n",
    "    processor=processor,\n",
    "    padding=True  \n",
    ")\n",
    "print(\"Data collator ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8225b8-fd3d-43ae-95ef-fba598eda7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "login(token=\"*****\")<insert hugging face hub login token>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5372d7-a071-4a8d-86d2-688e38b85881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e9859519656458095082e7597019e7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "423ad5bb8c1043e6acca631057b77928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wer_metric = evaluate.load(\"wer\")\n",
    "cer_metric = evaluate.load(\"cer\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    pred_ids = np.argmax(pred.predictions, axis=-1)\n",
    "    label_ids = pred.label_ids\n",
    "    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = processor.batch_decode(label_ids, group_tokens=False)\n",
    "    return {\n",
    "        \"wer\": wer_metric.compute(predictions=pred_str, references=label_str),\n",
    "        \"cer\": cer_metric.compute(predictions=pred_str, references=label_str),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b663010-119a-4cba-a717-9eead0ae24b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnikhita-james2\u001b[0m (\u001b[33mnikhita-james2-vellore-institute-of-technology\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6412f6d3-f21d-4ae6-a839-58ba9b89903d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_hidden_dropout(hidden_dropout, run_id):\n",
    "    print(f\"Training with hidden dropout: {hidden_dropout}\")\n",
    "    \n",
    "    model = AutoModelForCTC.from_pretrained(base_repo_name).to(\"cuda\")\n",
    "    model.freeze_feature_encoder()\n",
    "    model.config.hidden_dropout = hidden_dropout\n",
    "    \n",
    "    print(\" Updated classifier dropout to:\", hidden_dropout)\n",
    "    print(\" New hidden dropout:\", model.config.hidden_dropout)\n",
    "    output_dir = f\"/workspace/models/hidden_dropout_ablation_{run_id}\"\n",
    "    repo_name = f\"nik1509/telugu_wav2vec_hiddendropout_ablation_{run_id}\"\n",
    "    PARAMS = {\n",
    "        \"learning_rate\":5e-5,\n",
    "        \"epochs\": 15,\n",
    "        \"batch_size\": 8,\n",
    "        \"sampling_rate\": 16000\n",
    "    }\n",
    "    wandb.init(\n",
    "        project=\"telugu-asr-wav2vec_ablation\",\n",
    "        name=f\"dropoutablation_{hidden_dropout}\",\n",
    "        config={\n",
    "            \"learning_rate\": 5e-5, \n",
    "            \"hidden_dropout\": hidden_dropout,\n",
    "            \"freeze_feature_encoder\": True,\n",
    "            \"base_model\": base_repo_name\n",
    "        }\n",
    "    )\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        learning_rate=PARAMS[\"learning_rate\"],\n",
    "        per_device_train_batch_size=PARAMS[\"batch_size\"],\n",
    "        gradient_accumulation_steps=2,\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=700,\n",
    "        logging_steps=50,\n",
    "        save_steps=1500,\n",
    "        num_train_epochs=PARAMS[\"epochs\"],\n",
    "        gradient_checkpointing=True,\n",
    "        fp16=True,\n",
    "        warmup_ratio=0.1,\n",
    "        save_total_limit=2,\n",
    "        report_to=\"wandb\",\n",
    "        run_name=f\"dropout_ablation_{hidden_dropout}\",\n",
    "        push_to_hub=True,\n",
    "        hub_model_id=repo_name,\n",
    "        logging_dir=f\"{output_dir}/logs\"\n",
    "    )\n",
    "\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        tokenizer=processor,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    trainer.push_to_hub(commit_message=f\"Trained with hidden dropout {hidden_dropout}\")\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ecde16b-7b39-420f-b791-ecc8b70fff99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with hidden dropout: 0.2\n",
      " Updated classifier dropout to: 0.2\n",
      " New hidden dropout: 0.2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dropout_ablation_0.2</strong> at: <a href='https://wandb.ai/nikhita-james2-vellore-institute-of-technology/telugu-asr-wav2vec_ablation/runs/dnin2h4l' target=\"_blank\">https://wandb.ai/nikhita-james2-vellore-institute-of-technology/telugu-asr-wav2vec_ablation/runs/dnin2h4l</a><br> View project at: <a href='https://wandb.ai/nikhita-james2-vellore-institute-of-technology/telugu-asr-wav2vec_ablation' target=\"_blank\">https://wandb.ai/nikhita-james2-vellore-institute-of-technology/telugu-asr-wav2vec_ablation</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250625_185731-dnin2h4l/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250625_185748-t5lap82c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nikhita-james2-vellore-institute-of-technology/telugu-asr-wav2vec_ablation/runs/t5lap82c' target=\"_blank\">dropout_ablation_0.2</a></strong> to <a href='https://wandb.ai/nikhita-james2-vellore-institute-of-technology/telugu-asr-wav2vec_ablation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nikhita-james2-vellore-institute-of-technology/telugu-asr-wav2vec_ablation' target=\"_blank\">https://wandb.ai/nikhita-james2-vellore-institute-of-technology/telugu-asr-wav2vec_ablation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nikhita-james2-vellore-institute-of-technology/telugu-asr-wav2vec_ablation/runs/t5lap82c' target=\"_blank\">https://wandb.ai/nikhita-james2-vellore-institute-of-technology/telugu-asr-wav2vec_ablation/runs/t5lap82c</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_783/375773528.py:59: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17280' max='17280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17280/17280 7:58:35, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Wer</th>\n",
       "      <th>Cer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>309.466500</td>\n",
       "      <td>452.549011</td>\n",
       "      <td>0.422213</td>\n",
       "      <td>0.173327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>286.368600</td>\n",
       "      <td>454.056213</td>\n",
       "      <td>0.418434</td>\n",
       "      <td>0.171664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>306.547200</td>\n",
       "      <td>459.250671</td>\n",
       "      <td>0.412286</td>\n",
       "      <td>0.169973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>301.984100</td>\n",
       "      <td>461.250580</td>\n",
       "      <td>0.407717</td>\n",
       "      <td>0.169386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>320.239200</td>\n",
       "      <td>454.949524</td>\n",
       "      <td>0.409973</td>\n",
       "      <td>0.169551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>325.441800</td>\n",
       "      <td>464.644501</td>\n",
       "      <td>0.407717</td>\n",
       "      <td>0.168275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>276.407100</td>\n",
       "      <td>466.692352</td>\n",
       "      <td>0.407660</td>\n",
       "      <td>0.168598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>300.925800</td>\n",
       "      <td>461.080048</td>\n",
       "      <td>0.406701</td>\n",
       "      <td>0.168720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>287.149500</td>\n",
       "      <td>464.857697</td>\n",
       "      <td>0.406137</td>\n",
       "      <td>0.168899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>301.041700</td>\n",
       "      <td>464.345337</td>\n",
       "      <td>0.404671</td>\n",
       "      <td>0.168598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>315.138300</td>\n",
       "      <td>472.913330</td>\n",
       "      <td>0.405178</td>\n",
       "      <td>0.168376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>276.318800</td>\n",
       "      <td>471.850403</td>\n",
       "      <td>0.402866</td>\n",
       "      <td>0.168612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>263.142400</td>\n",
       "      <td>475.070221</td>\n",
       "      <td>0.400496</td>\n",
       "      <td>0.168397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>289.159700</td>\n",
       "      <td>480.321533</td>\n",
       "      <td>0.401173</td>\n",
       "      <td>0.168067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>322.226100</td>\n",
       "      <td>478.442719</td>\n",
       "      <td>0.403035</td>\n",
       "      <td>0.168376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>293.172100</td>\n",
       "      <td>475.662201</td>\n",
       "      <td>0.401060</td>\n",
       "      <td>0.168053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>303.560100</td>\n",
       "      <td>476.790771</td>\n",
       "      <td>0.398917</td>\n",
       "      <td>0.167272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>266.474400</td>\n",
       "      <td>483.872925</td>\n",
       "      <td>0.402922</td>\n",
       "      <td>0.167602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>293.339600</td>\n",
       "      <td>480.501953</td>\n",
       "      <td>0.400948</td>\n",
       "      <td>0.167602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>283.623400</td>\n",
       "      <td>475.516113</td>\n",
       "      <td>0.404840</td>\n",
       "      <td>0.168182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>229.080900</td>\n",
       "      <td>479.108368</td>\n",
       "      <td>0.401230</td>\n",
       "      <td>0.167430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>274.870900</td>\n",
       "      <td>483.676941</td>\n",
       "      <td>0.396999</td>\n",
       "      <td>0.166821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>285.821000</td>\n",
       "      <td>486.338684</td>\n",
       "      <td>0.402301</td>\n",
       "      <td>0.167731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>265.884000</td>\n",
       "      <td>495.378387</td>\n",
       "      <td>0.401907</td>\n",
       "      <td>0.168060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>286.316900</td>\n",
       "      <td>496.516479</td>\n",
       "      <td>0.397958</td>\n",
       "      <td>0.167559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>290.633600</td>\n",
       "      <td>496.384735</td>\n",
       "      <td>0.400835</td>\n",
       "      <td>0.167774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>271.668400</td>\n",
       "      <td>495.437744</td>\n",
       "      <td>0.400778</td>\n",
       "      <td>0.167824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>285.837100</td>\n",
       "      <td>496.080566</td>\n",
       "      <td>0.401117</td>\n",
       "      <td>0.167666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>286.389100</td>\n",
       "      <td>498.685486</td>\n",
       "      <td>0.397394</td>\n",
       "      <td>0.166900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>270.371000</td>\n",
       "      <td>496.679504</td>\n",
       "      <td>0.401343</td>\n",
       "      <td>0.167910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>294.988400</td>\n",
       "      <td>500.177368</td>\n",
       "      <td>0.402866</td>\n",
       "      <td>0.168662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>253.086500</td>\n",
       "      <td>505.822510</td>\n",
       "      <td>0.398635</td>\n",
       "      <td>0.167659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>287.726900</td>\n",
       "      <td>502.329681</td>\n",
       "      <td>0.394574</td>\n",
       "      <td>0.166713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>292.016400</td>\n",
       "      <td>510.101807</td>\n",
       "      <td>0.396209</td>\n",
       "      <td>0.167157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>262.278800</td>\n",
       "      <td>507.064270</td>\n",
       "      <td>0.399594</td>\n",
       "      <td>0.167802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>259.378400</td>\n",
       "      <td>518.080627</td>\n",
       "      <td>0.394574</td>\n",
       "      <td>0.166706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7400</td>\n",
       "      <td>289.343000</td>\n",
       "      <td>511.305176</td>\n",
       "      <td>0.397958</td>\n",
       "      <td>0.167451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7600</td>\n",
       "      <td>254.261100</td>\n",
       "      <td>508.289581</td>\n",
       "      <td>0.399650</td>\n",
       "      <td>0.168290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7800</td>\n",
       "      <td>251.138600</td>\n",
       "      <td>514.186096</td>\n",
       "      <td>0.395307</td>\n",
       "      <td>0.167480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>302.264300</td>\n",
       "      <td>512.470703</td>\n",
       "      <td>0.400496</td>\n",
       "      <td>0.167824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8200</td>\n",
       "      <td>256.029800</td>\n",
       "      <td>519.938171</td>\n",
       "      <td>0.402414</td>\n",
       "      <td>0.168877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>274.077400</td>\n",
       "      <td>516.314270</td>\n",
       "      <td>0.402471</td>\n",
       "      <td>0.169020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8600</td>\n",
       "      <td>264.743100</td>\n",
       "      <td>517.783447</td>\n",
       "      <td>0.402753</td>\n",
       "      <td>0.168311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8800</td>\n",
       "      <td>239.155900</td>\n",
       "      <td>520.689148</td>\n",
       "      <td>0.397845</td>\n",
       "      <td>0.168397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>264.812400</td>\n",
       "      <td>522.325806</td>\n",
       "      <td>0.399594</td>\n",
       "      <td>0.168555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9200</td>\n",
       "      <td>272.306900</td>\n",
       "      <td>518.951355</td>\n",
       "      <td>0.398804</td>\n",
       "      <td>0.167989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9400</td>\n",
       "      <td>257.879500</td>\n",
       "      <td>525.709106</td>\n",
       "      <td>0.399425</td>\n",
       "      <td>0.168598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9600</td>\n",
       "      <td>264.149400</td>\n",
       "      <td>530.191895</td>\n",
       "      <td>0.398748</td>\n",
       "      <td>0.168010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9800</td>\n",
       "      <td>221.568900</td>\n",
       "      <td>534.240723</td>\n",
       "      <td>0.397338</td>\n",
       "      <td>0.167781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>239.144200</td>\n",
       "      <td>535.238770</td>\n",
       "      <td>0.395984</td>\n",
       "      <td>0.168110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10200</td>\n",
       "      <td>288.363800</td>\n",
       "      <td>538.126953</td>\n",
       "      <td>0.397902</td>\n",
       "      <td>0.168390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10400</td>\n",
       "      <td>258.795500</td>\n",
       "      <td>540.169617</td>\n",
       "      <td>0.398917</td>\n",
       "      <td>0.168791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10600</td>\n",
       "      <td>231.556100</td>\n",
       "      <td>543.249573</td>\n",
       "      <td>0.394179</td>\n",
       "      <td>0.167645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10800</td>\n",
       "      <td>244.105900</td>\n",
       "      <td>547.540588</td>\n",
       "      <td>0.391584</td>\n",
       "      <td>0.167423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>243.236900</td>\n",
       "      <td>539.829773</td>\n",
       "      <td>0.397676</td>\n",
       "      <td>0.168282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11200</td>\n",
       "      <td>281.352300</td>\n",
       "      <td>546.856323</td>\n",
       "      <td>0.394404</td>\n",
       "      <td>0.167881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11400</td>\n",
       "      <td>219.857100</td>\n",
       "      <td>544.411987</td>\n",
       "      <td>0.396097</td>\n",
       "      <td>0.168333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11600</td>\n",
       "      <td>253.027100</td>\n",
       "      <td>551.070068</td>\n",
       "      <td>0.399312</td>\n",
       "      <td>0.168447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11800</td>\n",
       "      <td>246.571600</td>\n",
       "      <td>547.344727</td>\n",
       "      <td>0.398184</td>\n",
       "      <td>0.168196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>241.973000</td>\n",
       "      <td>549.051758</td>\n",
       "      <td>0.401060</td>\n",
       "      <td>0.169286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12200</td>\n",
       "      <td>213.980100</td>\n",
       "      <td>551.783020</td>\n",
       "      <td>0.395250</td>\n",
       "      <td>0.167702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12400</td>\n",
       "      <td>292.077100</td>\n",
       "      <td>553.742798</td>\n",
       "      <td>0.396830</td>\n",
       "      <td>0.168340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12600</td>\n",
       "      <td>224.012800</td>\n",
       "      <td>553.162598</td>\n",
       "      <td>0.395250</td>\n",
       "      <td>0.168125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12800</td>\n",
       "      <td>235.044900</td>\n",
       "      <td>562.999756</td>\n",
       "      <td>0.396209</td>\n",
       "      <td>0.168139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>234.584700</td>\n",
       "      <td>558.092041</td>\n",
       "      <td>0.395420</td>\n",
       "      <td>0.168626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13200</td>\n",
       "      <td>250.357400</td>\n",
       "      <td>553.912659</td>\n",
       "      <td>0.395589</td>\n",
       "      <td>0.168770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13400</td>\n",
       "      <td>221.669600</td>\n",
       "      <td>557.437561</td>\n",
       "      <td>0.395589</td>\n",
       "      <td>0.169372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13600</td>\n",
       "      <td>221.539500</td>\n",
       "      <td>554.738403</td>\n",
       "      <td>0.396773</td>\n",
       "      <td>0.169536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13800</td>\n",
       "      <td>248.961500</td>\n",
       "      <td>553.458008</td>\n",
       "      <td>0.399537</td>\n",
       "      <td>0.169214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>208.546400</td>\n",
       "      <td>573.225586</td>\n",
       "      <td>0.398691</td>\n",
       "      <td>0.169293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14200</td>\n",
       "      <td>245.520000</td>\n",
       "      <td>573.719971</td>\n",
       "      <td>0.393897</td>\n",
       "      <td>0.169228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14400</td>\n",
       "      <td>203.181500</td>\n",
       "      <td>562.344482</td>\n",
       "      <td>0.396322</td>\n",
       "      <td>0.169938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14600</td>\n",
       "      <td>243.693400</td>\n",
       "      <td>565.296387</td>\n",
       "      <td>0.397056</td>\n",
       "      <td>0.169429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14800</td>\n",
       "      <td>239.919700</td>\n",
       "      <td>570.505859</td>\n",
       "      <td>0.393558</td>\n",
       "      <td>0.168677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>255.085500</td>\n",
       "      <td>565.106262</td>\n",
       "      <td>0.396604</td>\n",
       "      <td>0.169386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15200</td>\n",
       "      <td>227.970800</td>\n",
       "      <td>574.391602</td>\n",
       "      <td>0.397281</td>\n",
       "      <td>0.170325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15400</td>\n",
       "      <td>223.800400</td>\n",
       "      <td>575.307373</td>\n",
       "      <td>0.396153</td>\n",
       "      <td>0.169909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15600</td>\n",
       "      <td>206.173000</td>\n",
       "      <td>575.749207</td>\n",
       "      <td>0.397394</td>\n",
       "      <td>0.170016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15800</td>\n",
       "      <td>258.389300</td>\n",
       "      <td>567.948120</td>\n",
       "      <td>0.397450</td>\n",
       "      <td>0.171005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>225.787800</td>\n",
       "      <td>571.484619</td>\n",
       "      <td>0.397225</td>\n",
       "      <td>0.170160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16200</td>\n",
       "      <td>227.581600</td>\n",
       "      <td>576.980591</td>\n",
       "      <td>0.394856</td>\n",
       "      <td>0.170461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16400</td>\n",
       "      <td>233.990800</td>\n",
       "      <td>584.738831</td>\n",
       "      <td>0.396435</td>\n",
       "      <td>0.170547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16600</td>\n",
       "      <td>256.342400</td>\n",
       "      <td>582.925110</td>\n",
       "      <td>0.396379</td>\n",
       "      <td>0.170368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16800</td>\n",
       "      <td>202.179100</td>\n",
       "      <td>585.197876</td>\n",
       "      <td>0.395363</td>\n",
       "      <td>0.170504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>234.957200</td>\n",
       "      <td>585.935791</td>\n",
       "      <td>0.395476</td>\n",
       "      <td>0.169694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17200</td>\n",
       "      <td>203.269300</td>\n",
       "      <td>584.245605</td>\n",
       "      <td>0.398014</td>\n",
       "      <td>0.170625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/cer</td><td>█▅▃▄▄▃▂▁▂▃▃▃▄▂▁▃▁▂▃▂▄▃▃▃▃▃▄▂▃▃▄▄▅▅▅▆▆▆▆▆</td></tr><tr><td>eval/loss</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▄▄▄▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇██</td></tr><tr><td>eval/runtime</td><td>█▄▄▃▄▄▇▄▇▄▃▅▅▄▂▂▂▁▂▁▁▂▁▁▂▁▂▁▂▃▂▃▄▂▂▂▂▂▂▁</td></tr><tr><td>eval/samples_per_second</td><td>▅▄▅▄▁▄▃▆▁▄▄▆▄▃▅▅▆▆▇▇▇█▇▆▆▆▇▇▇▇▆▅▆▆▇▅▆▆▆▅</td></tr><tr><td>eval/steps_per_second</td><td>▄▅▂▁▅▄▇▂▅▅▅▆▆▅▅▇▆▆▇██▇▇▇▆▇▇▇▇▇▆▆▆▅▅▇▆▇▆▇</td></tr><tr><td>eval/wer</td><td>█▆▆▆▆▃▄▄▃▂▃▄▄▃▂▂▃▁▃▄▄▂▃▃▃▂▁▃▂▄▁▁▁▃▂▂▂▂▁▂</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇█</td></tr><tr><td>train/grad_norm</td><td>▆▃▆▃▅▂▂▂▂▂▂▂▃▂▃▂▃▃▇▂█▁▄▃▅▅█▁▂▇▃▃▂▂▄▄▅▂█▅</td></tr><tr><td>train/learning_rate</td><td>▁▂▂▆██████▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆▆▆▅▅▅▅▅▅▅▄</td></tr><tr><td>train/loss</td><td>█▆▇▆▅▅█▄▆▃▅▇▅▅▅▆▆▄▄▄▃▄▄▄▃▃▁▄▂▂▃▁▄▃▃▂▃▂▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/cer</td><td>0.17063</td></tr><tr><td>eval/loss</td><td>584.24561</td></tr><tr><td>eval/runtime</td><td>99.8038</td></tr><tr><td>eval/samples_per_second</td><td>20.52</td></tr><tr><td>eval/steps_per_second</td><td>2.565</td></tr><tr><td>eval/wer</td><td>0.39801</td></tr><tr><td>total_flos</td><td>5.995827423689016e+19</td></tr><tr><td>train/epoch</td><td>15</td></tr><tr><td>train/global_step</td><td>17280</td></tr><tr><td>train/grad_norm</td><td>308.49826</td></tr><tr><td>train/learning_rate</td><td>3e-05</td></tr><tr><td>train/loss</td><td>225.7413</td></tr><tr><td>train_loss</td><td>264.90665</td></tr><tr><td>train_runtime</td><td>28717.1712</td></tr><tr><td>train_samples_per_second</td><td>9.626</td></tr><tr><td>train_steps_per_second</td><td>0.602</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dropout_ablation_0.2</strong> at: <a href='https://wandb.ai/nikhita-james2-vellore-institute-of-technology/telugu-asr-wav2vec_ablation/runs/t5lap82c' target=\"_blank\">https://wandb.ai/nikhita-james2-vellore-institute-of-technology/telugu-asr-wav2vec_ablation/runs/t5lap82c</a><br> View project at: <a href='https://wandb.ai/nikhita-james2-vellore-institute-of-technology/telugu-asr-wav2vec_ablation' target=\"_blank\">https://wandb.ai/nikhita-james2-vellore-institute-of-technology/telugu-asr-wav2vec_ablation</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250625_185748-t5lap82c/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_with_hidden_dropout(0.2, \"hd_02\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "de56ba14-0bc2-454b-9b8b-2ceb6dd81888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with hidden dropout: 0.3\n",
      " Updated classifier dropout to: 0.3\n",
      " New hidden dropout: 0.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250626_050634-1f0eg0l0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nikhita-james2-vellore-institute-of-technology/telugu-asr-wav2vec_ablation/runs/1f0eg0l0' target=\"_blank\">dropoutablation_0.3</a></strong> to <a href='https://wandb.ai/nikhita-james2-vellore-institute-of-technology/telugu-asr-wav2vec_ablation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nikhita-james2-vellore-institute-of-technology/telugu-asr-wav2vec_ablation' target=\"_blank\">https://wandb.ai/nikhita-james2-vellore-institute-of-technology/telugu-asr-wav2vec_ablation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nikhita-james2-vellore-institute-of-technology/telugu-asr-wav2vec_ablation/runs/1f0eg0l0' target=\"_blank\">https://wandb.ai/nikhita-james2-vellore-institute-of-technology/telugu-asr-wav2vec_ablation/runs/1f0eg0l0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_783/2647638347.py:59: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17280' max='17280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17280/17280 6:10:18, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Wer</th>\n",
       "      <th>Cer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>336.525900</td>\n",
       "      <td>454.976227</td>\n",
       "      <td>0.413470</td>\n",
       "      <td>0.171070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>275.635400</td>\n",
       "      <td>472.184418</td>\n",
       "      <td>0.406137</td>\n",
       "      <td>0.168619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>288.286900</td>\n",
       "      <td>468.271118</td>\n",
       "      <td>0.407604</td>\n",
       "      <td>0.169400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>285.009200</td>\n",
       "      <td>474.086578</td>\n",
       "      <td>0.407547</td>\n",
       "      <td>0.169307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>286.370600</td>\n",
       "      <td>487.920776</td>\n",
       "      <td>0.403768</td>\n",
       "      <td>0.167100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>227.290200</td>\n",
       "      <td>485.690979</td>\n",
       "      <td>0.398635</td>\n",
       "      <td>0.168024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>253.165300</td>\n",
       "      <td>494.035461</td>\n",
       "      <td>0.403035</td>\n",
       "      <td>0.167960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>285.785100</td>\n",
       "      <td>498.219604</td>\n",
       "      <td>0.399481</td>\n",
       "      <td>0.167286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>252.804200</td>\n",
       "      <td>500.894287</td>\n",
       "      <td>0.401173</td>\n",
       "      <td>0.167946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>260.786700</td>\n",
       "      <td>514.076294</td>\n",
       "      <td>0.390963</td>\n",
       "      <td>0.166104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7700</td>\n",
       "      <td>267.560700</td>\n",
       "      <td>511.081757</td>\n",
       "      <td>0.395815</td>\n",
       "      <td>0.167100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>278.114800</td>\n",
       "      <td>520.340027</td>\n",
       "      <td>0.395138</td>\n",
       "      <td>0.167107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9100</td>\n",
       "      <td>266.061800</td>\n",
       "      <td>520.492310</td>\n",
       "      <td>0.394292</td>\n",
       "      <td>0.167573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9800</td>\n",
       "      <td>222.710400</td>\n",
       "      <td>529.575378</td>\n",
       "      <td>0.394743</td>\n",
       "      <td>0.168003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>238.997000</td>\n",
       "      <td>539.867737</td>\n",
       "      <td>0.395532</td>\n",
       "      <td>0.168282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11200</td>\n",
       "      <td>279.455400</td>\n",
       "      <td>539.716919</td>\n",
       "      <td>0.397676</td>\n",
       "      <td>0.168548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11900</td>\n",
       "      <td>246.471100</td>\n",
       "      <td>549.153015</td>\n",
       "      <td>0.396322</td>\n",
       "      <td>0.168017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12600</td>\n",
       "      <td>227.025700</td>\n",
       "      <td>546.250244</td>\n",
       "      <td>0.393953</td>\n",
       "      <td>0.168311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13300</td>\n",
       "      <td>257.304100</td>\n",
       "      <td>555.305298</td>\n",
       "      <td>0.395758</td>\n",
       "      <td>0.168311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>207.406500</td>\n",
       "      <td>571.108643</td>\n",
       "      <td>0.396830</td>\n",
       "      <td>0.168805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14700</td>\n",
       "      <td>262.207600</td>\n",
       "      <td>565.413208</td>\n",
       "      <td>0.395138</td>\n",
       "      <td>0.169128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15400</td>\n",
       "      <td>220.287600</td>\n",
       "      <td>577.410889</td>\n",
       "      <td>0.391866</td>\n",
       "      <td>0.168368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16100</td>\n",
       "      <td>251.858400</td>\n",
       "      <td>575.307922</td>\n",
       "      <td>0.396379</td>\n",
       "      <td>0.168691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16800</td>\n",
       "      <td>202.125700</td>\n",
       "      <td>583.593384</td>\n",
       "      <td>0.394574</td>\n",
       "      <td>0.169164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/cer</td><td>█▅▆▆▂▄▄▃▄▁▂▂▃▄▄▄▄▄▄▅▅▄▅▅</td></tr><tr><td>eval/loss</td><td>▁▂▂▂▃▃▃▃▃▄▄▅▅▅▆▆▆▆▆▇▇███</td></tr><tr><td>eval/runtime</td><td>▂▁▄▆▁▄▄▄█▅▂▄█▃▆▆▇▂▂▄▄▅▃▇</td></tr><tr><td>eval/samples_per_second</td><td>▇█▅▃█▅▅▅▁▄▇▅▁▆▃▃▂▇▇▅▅▄▆▂</td></tr><tr><td>eval/steps_per_second</td><td>▇█▅▃█▅▅▅▁▄▇▅▁▆▃▃▂▇▇▅▄▄▆▂</td></tr><tr><td>eval/wer</td><td>█▆▆▆▅▃▅▄▄▁▃▂▂▂▂▃▃▂▂▃▂▁▃▂</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▄▄▄▄▄▄▄▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇███</td></tr><tr><td>train/grad_norm</td><td>▃▂▄▆▁▁▁▂▆▂▆▂▁▂▂▃▁▃▄▅▄▂▁█▇▄▁▃▄▂▄▃▅▇▂▁▁▂▃▁</td></tr><tr><td>train/learning_rate</td><td>▁▂▃▄██████▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▄</td></tr><tr><td>train/loss</td><td>█▇██▇▅▅▆▇▇▅▆▆▆▄▅▄▅▄▆▅▄▅▃▅▆▅▅▄▂▅▅▃▄▂▃▁▂▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/cer</td><td>0.16916</td></tr><tr><td>eval/loss</td><td>583.59338</td></tr><tr><td>eval/runtime</td><td>106.243</td></tr><tr><td>eval/samples_per_second</td><td>19.277</td></tr><tr><td>eval/steps_per_second</td><td>2.41</td></tr><tr><td>eval/wer</td><td>0.39457</td></tr><tr><td>total_flos</td><td>5.995827423689016e+19</td></tr><tr><td>train/epoch</td><td>15</td></tr><tr><td>train/global_step</td><td>17280</td></tr><tr><td>train/grad_norm</td><td>341.66656</td></tr><tr><td>train/learning_rate</td><td>3e-05</td></tr><tr><td>train/loss</td><td>226.8049</td></tr><tr><td>train_loss</td><td>264.84451</td></tr><tr><td>train_runtime</td><td>22220.3396</td></tr><tr><td>train_samples_per_second</td><td>12.44</td></tr><tr><td>train_steps_per_second</td><td>0.778</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dropoutablation_0.3</strong> at: <a href='https://wandb.ai/nikhita-james2-vellore-institute-of-technology/telugu-asr-wav2vec_ablation/runs/1f0eg0l0' target=\"_blank\">https://wandb.ai/nikhita-james2-vellore-institute-of-technology/telugu-asr-wav2vec_ablation/runs/1f0eg0l0</a><br> View project at: <a href='https://wandb.ai/nikhita-james2-vellore-institute-of-technology/telugu-asr-wav2vec_ablation' target=\"_blank\">https://wandb.ai/nikhita-james2-vellore-institute-of-technology/telugu-asr-wav2vec_ablation</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250626_050634-1f0eg0l0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_with_hidden_dropout(0.3, \"hd_03\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "641dbb2d-878e-4b12-81f7-e0a44c24d10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoProcessor, AutoModelForCTC\n",
    "import evaluate\n",
    "\n",
    "wer_metric = evaluate.load(\"wer\")\n",
    "cer_metric = evaluate.load(\"cer\")\n",
    "\n",
    "def evaluate_model(repo_name: str, test_dataset):\n",
    "    print(f\"\\nEvaluating: {repo_name}\")\n",
    "    processor = AutoProcessor.from_pretrained(repo_name)\n",
    "    model = AutoModelForCTC.from_pretrained(repo_name).to(\"cuda\")\n",
    "    model.eval()\n",
    "\n",
    "    def map_to_prediction(batch):\n",
    "        with torch.no_grad():\n",
    "            input_values = torch.tensor(batch[\"input_values\"], device=\"cuda\").unsqueeze(0)\n",
    "            logits = model(input_values).logits\n",
    "            pred_ids = torch.argmax(logits, dim=-1)\n",
    "            batch[\"pred_str\"] = processor.batch_decode(pred_ids)[0]\n",
    "            batch[\"text\"] = processor.decode(batch[\"labels\"], group_tokens=False)\n",
    "        return batch\n",
    "\n",
    "    results = test_dataset.map(map_to_prediction, remove_columns=test_dataset.column_names)\n",
    "\n",
    "    wer = wer_metric.compute(predictions=results[\"pred_str\"], references=results[\"text\"])\n",
    "    cer = cer_metric.compute(predictions=results[\"pred_str\"], references=results[\"text\"])\n",
    "    \n",
    "    print(f\"WER for {repo_name}: {wer:.4f}\")\n",
    "    print(f\"CER for {repo_name}: {cer:.4f}\")\n",
    "    \n",
    "    return wer, cer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2c5115d9-4949-4766-8b82-f62e7598a35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating: nik1509/telugu_wav2vec_hidden_dropout_ablation_hd_02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0704e902eaab4ee0962160afbeeba198",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/256 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c1c7594a0d34534b39359e4d32ae948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76f501101e4d4bc59099397639381ace",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/985 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35e4128700a14e798592f04731c473fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/45.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5a90cc0394d41b3b53621f87df6f9eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/548 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "228dc069c4cc498194d40acb8b3f47b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a9a2ff3456d4e2996efc2172ac50b82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.26G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function evaluate_model.<locals>.map_to_prediction at 0x7a129c581f30> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75f1342fabff474380039fedd7955943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2048 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER for nik1509/telugu_wav2vec_hidden_dropout_ablation_hd_02: 0.3779\n",
      "CER for nik1509/telugu_wav2vec_hidden_dropout_ablation_hd_02: 0.1617\n",
      "\n",
      "Evaluating: nik1509/telugu_wav2vec_hiddendropout_ablation_hd_03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dac7a0facbb4f7d98332bf3ffafded3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/256 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab094970d1af4bdf866ce27a6f7d1aab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "273d1135614946a6b8277cf44d756e56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/985 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f08995003d8f4fd09a4130c734cba57b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/45.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c4bb876bc444ae09b71a87247f770c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/548 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9abb4fd9f544455fa2bcb50722d789de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78f659e8115e49fb84f47c6710a1ee4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.26G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31df4bbf0c4246caaf3e41c3dd2c781d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2048 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER for nik1509/telugu_wav2vec_hiddendropout_ablation_hd_03: 0.3747\n",
      "CER for nik1509/telugu_wav2vec_hiddendropout_ablation_hd_03: 0.1612\n",
      "Evaluation for nik1509/telugu_wav2vec_hidden_dropout_ablation_hd_02:\n",
      "WER: 0.3779 | CER: 0.1617\n",
      "\n",
      "Evaluation for nik1509/telugu_wav2vec_hiddendropout_ablation_hd_03:\n",
      "WER: 0.3747 | CER: 0.1612\n",
      "\n"
     ]
    }
   ],
   "source": [
    "repo_names = [\n",
    "    \"nik1509/telugu_wav2vec_hidden_dropout_ablation_hd_02\",\n",
    "    \"nik1509/telugu_wav2vec_hiddendropout_ablation_hd_03\"\n",
    "]\n",
    "\n",
    "results_dict = {}\n",
    "for repo in repo_names:\n",
    "    wer, cer = evaluate_model(repo, val_dataset) \n",
    "    results_dict[repo] = {\"WER\": wer, \"CER\": cer}\n",
    "\n",
    "for k, v in results_dict.items():\n",
    "    print(f\"Evaluation for {k}:\\nWER: {v['WER']:.4f} | CER: {v['CER']:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9fc0d2-a64d-4079-bc7e-693c4f919515",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
